{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa+AoC9FEfMc7zCE/PCO/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asritha0606/GenerativeAI/blob/main/Assignments_GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eZdBH0X3Ayn",
        "outputId": "19ea8973-07d9-41f0-db00-ca4b33a2397d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/129.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api')\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key"
      ],
      "metadata": {
        "id": "jJ2mUdhV31_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of large language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\",\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcpGjLWz4GwO",
        "outputId": "100f0bd0-a380-4c5f-e03b-0688f22ad400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large language models, such as transformer-based models like BERT, RoBERTa, and XLNet, have revolutionized the field of natural language processing (NLP) and have numerous implications across various domains. Here are some of the key reasons why large language models are important:\n",
            "\n",
            "1. **Improved NLP capabilities**: Large language models have significantly improved the accuracy of various NLP tasks, such as:\n",
            "\t* Text classification\n",
            "\t* Sentiment analysis\n",
            "\t* Named entity recognition\n",
            "\t* Question answering\n",
            "\t* Machine translation\n",
            "\t* Language generation\n",
            "2. **Increased efficiency**: These models can process large amounts of text data quickly and efficiently, making them suitable for applications that require rapid text analysis, such as:\n",
            "\t* Sentiment analysis in real-time\n",
            "\t* Text classification for spam detection\n",
            "\t* Automatic summarization\n",
            "3. **Multitask learning**: Large language models can be pre-trained on multiple tasks simultaneously, allowing them to learn general language representations that can be fine-tuned for specific tasks, such as:\n",
            "\t* Language translation\n",
            "\t* Question answering\n",
            "\t* Text generation\n",
            "4. **Transfer learning**: These models can be fine-tuned for specific tasks, reducing the need for large amounts of task-specific data and annotations, making them cost-effective and efficient.\n",
            "5. **Advancements in understanding language**: Large language models have helped us better understand language phenomena, such as:\n",
            "\t* Contextual dependencies\n",
            "\t* Ambiguity and polysemy\n",
            "\t* Idioms and figurative language\n",
            "\t* Syntactic and semantic relationships\n",
            "6. **Improved dialogue systems**: Large language models have enabled significant improvements in dialogue systems, such as:\n",
            "\t* Conversational agents\n",
            "\t* Chatbots\n",
            "\t* Voice assistants\n",
            "7. **Content generation**: Large language models can generate high-quality content, such as:\n",
            "\t* Short-form text\n",
            "\t* Summaries\n",
            "\t* Articles\n",
            "\t* Product descriptions\n",
            "8. **Enhanced customer experience**: These models can be used to improve customer service, such as:\n",
            "\t* Chatbots for customer support\n",
            "\t* Sentiment analysis for customer feedback\n",
            "\t* Content generation for personalized marketing\n",
            "9. **Research and development**: Large language models have accelerated research in NLP, enabling the development of new techniques, such as:\n",
            "\t* Attention mechanisms\n",
            "\t* Graph-based models\n",
            "\t* Multi-hop reasoning\n",
            "10. **Potential applications**: The potential applications of large language models are vast and varied, including:\n",
            "\t* Healthcare (e.g., patient diagnosis, medical record analysis)\n",
            "\t* Finance (e.g., text-based financial analysis, sentiment analysis)\n",
            "\t* Law enforcement (e.g., document analysis, language-based crime detection)\n",
            "\t* Education (e.g., adaptive learning systems, personalized tutoring)\n",
            "\n",
            "In summary, large language models have revolutionized the field of NLP, enabling significant improvements in various applications and research areas. Their importance lies in their ability to analyze and generate large amounts of text data efficiently, while providing insights into language itself and enabling the development of more sophisticated applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 1: Summary Extraction"
      ],
      "metadata": {
        "id": "NMgL6g8s5COY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove special symbols and multiple punctuation\n",
        "    text = re.sub(r'[^\\w\\s\\.\\,\\-\\']', ' ', text)  # keep alphanumerics and punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)  # replace multiple spaces with one\n",
        "    text = re.sub(r'\\.\\.+', '.', text)  # replace ellipses with a single period\n",
        "    text = re.sub(r'(?<=\\w)[A-Z]', lambda x: ' ' + x.group(0), text)  # fix camel-case issues\n",
        "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)  # remove space before punctuation\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "r27Hg7U95EeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text):\n",
        "    cleaned = clean_text(text)\n",
        "    prompt = f\"Summarise my text: {cleaned}\"\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "XXXt2lv95IC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"\"\"\n",
        "Black..... holes—those mysterious cosmic phenomena—are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha### have dived deeply into the “science” of these objects, uncovering fascinating insights! According to Rothwell’s research (2021), black holes form when massive stars burn ^^^^through their fuel & collapse under gravity until they reach a singularity—a point of (nearly) infinite density, where physics bReak dOwn.\n",
        "\n",
        "Sinha’s studies focus on the event horizon, or the “point of no return”; any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation—a theoretical ....concept from Stephen Hawking—suggesting that black holes.... emit small amounts of energy...., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities!!!!. Together, Rothwell and Sinha’s studies hint at bridging quantum mechanics w/ general relativity—fields otherwise tough to reconcile!\n",
        "\"\"\"\n",
        "\n",
        "cleaned = clean_text(raw_text)\n",
        "prompt = summarize_text(raw_text)\n",
        "\n",
        "print(\"Cleaned Text:\\n\", cleaned)\n",
        "print(\"\\nPrompt:\\n\", prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sesDpU8X5JMa",
        "outputId": "475d1e17-bb50-48bf-b3fa-4518f46565f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            " Black. holes those mysterious cosmic phenomena are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have dived deeply into the science of these objects, uncovering fascinating insights According to Rothwell s research 2021, black holes form when massive stars burn through their fuel collapse under gravity until they reach a singularity a point of nearly infinite density, where physics b Reak d Own. Sinha s studies focus on the event horizon, or the point of no return any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation a theoretical .concept from Stephen Hawking suggesting that black holes. emit small amounts of energy., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities. Together, Rothwell and Sinha s studies hint at bridging quantum mechanics w general relativity fields otherwise tough to reconcile\n",
            "\n",
            "Prompt:\n",
            " Summarise my text: Black. holes those mysterious cosmic phenomena are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have dived deeply into the science of these objects, uncovering fascinating insights According to Rothwell s research 2021, black holes form when massive stars burn through their fuel collapse under gravity until they reach a singularity a point of nearly infinite density, where physics b Reak d Own. Sinha s studies focus on the event horizon, or the point of no return any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation a theoretical .concept from Stephen Hawking suggesting that black holes. emit small amounts of energy., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities. Together, Rothwell and Sinha s studies hint at bridging quantum mechanics w general relativity fields otherwise tough to reconcile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q litellm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cQh7gje6D2f",
        "outputId": "5030d537-fac9-4649-9b91-8668e666e189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion"
      ],
      "metadata": {
        "id": "WwIVqTt_6Ao1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt):\n",
        "  #define model\n",
        "  model=\"groq/llama3-70b-8192\"\n",
        "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "  #call responses\n",
        "  response = completion(\n",
        "      model=model,\n",
        "      messages=messages\n",
        "  )\n",
        "\n",
        "  return response['choices'][0]['message']['content'] or \"\"\n"
      ],
      "metadata": {
        "id": "PlQNQofx514D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = get_response(prompt)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQQe5PKi53Yh",
        "outputId": "7e144d77-cdfb-4866-fb46-493b047a87b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a summary of your text:\n",
            "\n",
            "Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have made significant discoveries about black holes, regions of intense gravity where not even light can escape. Rothwell's research reveals that black holes are created when massive stars collapse into a singularity, a point of infinite density where physics breaks down. She focuses on the event horizon, where anything that crosses it (including light) is trapped forever. Her studies also explore Hawking Radiation theory, which suggests that black holes emit small amounts of radiation, allowing scientists to peek inside. Their combined research hints at bridging the gap between quantum mechanics and general relativity, two fields previously hard to reconcile.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 2: Sentiment Analysis"
      ],
      "metadata": {
        "id": "-0cAksU5aah8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(review):\n",
        "    prompt = f\"\"\"\n",
        "Your task is to classify the sentiment of a user's review as Positive, Negative, or Neutral.\n",
        "\n",
        "<review>: I absolutely loved the new update—it’s so user-friendly and fast!\n",
        "<sentiment>: Positive\n",
        "\n",
        "<review>: {review}\n",
        "<sentiment>:\"\"\"\n",
        "\n",
        "    return get_response(prompt).strip()\n"
      ],
      "metadata": {
        "id": "tljEOFZD6W9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"The app crashes every time I try to upload a file.\"\n",
        "sentiment = get_sentiment(review)\n",
        "print(\"Sentiment:\", sentiment)\n"
      ],
      "metadata": {
        "id": "piDpHDZr7ygD",
        "outputId": "f6834247-97c2-4938-9e20-3b3417b488ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: <sentiment>: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 3: Intelligent Resume Filtering using Keyword Extraction\n"
      ],
      "metadata": {
        "id": "d9WBS_YdaTVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Approach"
      ],
      "metadata": {
        "id": "b_HgmFzVaQF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_hiring_query(query):\n",
        "    filters = {\n",
        "        \"work_experience\": None,\n",
        "        \"technical_skills\": [],\n",
        "        \"designation\": None,\n",
        "        \"education\": None,\n",
        "        \"location\": None\n",
        "    }\n",
        "\n",
        "    # Lowercase for normalization\n",
        "    q = query.lower()\n",
        "\n",
        "    # 1. Extract years of experience\n",
        "    match = re.search(r'(\\d+)\\s+years?', q)\n",
        "    if match:\n",
        "        filters[\"work_experience\"] = int(match.group(1))\n",
        "\n",
        "    # 2. Extract skills - define a known skill list (can be from DB)\n",
        "    known_skills = ['python', 'java', 'flask', 'react', 'nodejs', 'sql', 'mongodb', 'c++', 'aws', 'docker']\n",
        "    for skill in known_skills:\n",
        "        if re.search(rf'\\b{skill}\\b', q):\n",
        "            filters[\"technical_skills\"].append(skill)\n",
        "\n",
        "    # 3. Extract location - look for \"in <location>\" or \"at <location>\" or \"work in <location>\"\n",
        "    loc_match = re.search(r'(?:in|at|work in)\\s+([a-zA-Z\\s]+)', q)\n",
        "    if loc_match:\n",
        "        location = loc_match.group(1).strip().title()\n",
        "        filters[\"location\"] = location\n",
        "\n",
        "    # Build MongoDB query\n",
        "    mongo_query = {}\n",
        "\n",
        "    if filters[\"work_experience\"] is not None:\n",
        "        mongo_query[\"work_experience\"] = {\"$eq\": filters[\"work_experience\"]}\n",
        "\n",
        "    if filters[\"technical_skills\"]:\n",
        "        mongo_query[\"technical_skills\"] = {\"$in\": filters[\"technical_skills\"]}\n",
        "\n",
        "    if filters[\"location\"]:\n",
        "        mongo_query[\"location\"] = {\"$regex\": filters[\"location\"], \"$options\": \"i\"}\n",
        "\n",
        "    return mongo_query\n"
      ],
      "metadata": {
        "id": "IRj33AgrW2z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Get me candidates with 2 years experience in python and flask and ready to work in Banglore\"\n",
        "print(parse_hiring_query(query))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsMDX90yW--i",
        "outputId": "a6c05ede-3258-4828-d284-cb305aba64e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'work_experience': {'$eq': 2}, 'technical_skills': {'$in': ['python', 'flask']}, 'location': {'$regex': 'Python And Flask And Ready To Work In Banglore', '$options': 'i'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM-based prompt"
      ],
      "metadata": {
        "id": "ROBC_p1XaNGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "import ast\n",
        "\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "FILTERS = [\"work_experience\", \"technical_skills\", \"designation\", \"education\", \"location\"]\n",
        "\n",
        "def generate_llm_prompt(query: str):\n",
        "    return f\"\"\"\n",
        "You are an expert MongoDB engineer.\n",
        "Your job is to extract keywords from a hiring manager's query and return a VALID PyMongo query.\n",
        "\n",
        "Filters to consider:\n",
        "{FILTERS}\n",
        "\n",
        "Instructions:\n",
        "1. Map experience (e.g., \"3 years\") to `work_experience.years`.\n",
        "2. Map skills (e.g., \"Python\", \"Flask\") to `technical_skills.skill`.\n",
        "3. Map places (e.g., \"Bangalore\", \"Delhi\") to `location`.\n",
        "4. Use `$gte` for experience comparisons.\n",
        "5. Use `$in` for lists.\n",
        "6. Only return the MongoDB query (as a Python dictionary). No explanation.\n",
        "\n",
        "Hiring Manager Query:\n",
        "\\\"{query}\\\"\n",
        "\"\"\"\n",
        "\n",
        "def get_mongodb_query_from_llm(prompt: str):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    # Extract and safely evaluate the dictionary\n",
        "    raw_query = response.choices[0].message.content.strip()\n",
        "\n",
        "    try:\n",
        "        parsed_query = ast.literal_eval(raw_query)\n",
        "        return parsed_query\n",
        "    except Exception as e:\n",
        "        print(\"Error parsing query:\", e)\n",
        "        print(\"Raw output:\", raw_query)\n",
        "        return {}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    hiring_query = \"I want candidates with 3 years experience in Java or Node.js, based in Delhi\"\n",
        "    prompt = generate_llm_prompt(hiring_query)\n",
        "    mongo_query = get_mongodb_query_from_llm(prompt)\n",
        "\n",
        "    print(\"MongoDB Query:\")\n",
        "    print(mongo_query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyOBnv2vZcN9",
        "outputId": "95aeda8f-0372-4e24-e0e8-37eee2212b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MongoDB Query:\n",
            "{'$and': [{'work_experience.years': {'$gte': 3}}, {'technical_skills.skill': {'$in': ['Java', 'Node.js']}}, {'location': 'Delhi'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment: Building a Smart Assistant for Virtual Healthcare Support"
      ],
      "metadata": {
        "id": "jKT-SvU2sh0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement: Given a doctor-patient conversation, the AI assistant should help by:\n",
        "\n",
        "Detecting the patient's emotional state. Give a score on a scale of 1-5.\n",
        "Summarizing the chief complaint and urgency of the patient.\n",
        "\n"
      ],
      "metadata": {
        "id": "pOZoZrCGsuzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Tools:\n",
        "\n",
        "*   EmotionDetectionTool: analyzes patient’s emotional state and returns an emotion label + score (1-5).\n",
        "\n",
        "*   ChiefComplaintSummaryTool: summarizes the patient's main complaint and assesses urgency.\n",
        "\n"
      ],
      "metadata": {
        "id": "z-shz-8cw5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q groq langchain-groq langchain langchain-community langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhtf38qnLknP",
        "outputId": "1a05d7cd-6bca-4284-fcd1-9939e3643c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q litellm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lJDzOgWLnZK",
        "outputId": "afc1ec8a-2048-48e1-b01c-771f48228f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api')\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key"
      ],
      "metadata": {
        "id": "9YxdHPaLLqo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.tools import tool\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from typing import List\n",
        "from litellm import completion\n",
        "from langchain.agents import initialize_agent, Tool, AgentType"
      ],
      "metadata": {
        "id": "-dXveAimLrPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\", #\"llama-3.1-8b-instant\",\n",
        "    temperature=0, # range of temperature variable is from 0(least artistic) to 1(most artistic/enhanced)\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "OUoskUaZLtdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_core.language_models import BaseLanguageModel\n",
        "\n",
        "# Assume this is your LLM instance (already initialized, e.g., with ChatOpenAI or ChatGroq)\n",
        "# llm = ...\n",
        "\n",
        "@tool\n",
        "def detect_patient_emotion(conversation: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyzes a doctor-patient conversation to extract:\n",
        "    1. Patient's emotion (e.g., anxious, calm, in pain)\n",
        "    2. Emotion score on a scale from 1 to 5 (1 = very distressed, 5 = calm)\n",
        "\n",
        "    Parameters:\n",
        "    - conversation (str): The full conversation text.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Contains \"emotion\" and \"emotion_score\" as keys.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following conversation between a doctor and a patient.\n",
        "\n",
        "    Extract only:\n",
        "    - Patient's primary emotional state (one word)\n",
        "    - Emotion score from 1 to 5 (1 = very distressed, 5 = calm)\n",
        "\n",
        "    Format your response exactly like this:\n",
        "    emotion: <emotion>\n",
        "    emotion_score: <score>\n",
        "\n",
        "    Conversation:\n",
        "    {conversation}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    raw_output = response.content.strip()\n",
        "\n",
        "    # Simple parsing without using Pydantic\n",
        "    result = {}\n",
        "    for line in raw_output.splitlines():\n",
        "        if \":\" in line:\n",
        "            key, value = line.split(\":\", 1)\n",
        "            result[key.strip()] = value.strip()\n",
        "\n",
        "    # Optional: Convert score to int\n",
        "    try:\n",
        "        result[\"emotion_score\"] = int(result[\"emotion_score\"])\n",
        "    except:\n",
        "        result[\"emotion_score\"] = None  # fallback if score parsing fails\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "4fbSkLDIsgDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def summarize_chief_complaint(conversation: str) -> dict:\n",
        "    \"\"\"\n",
        "    Summarizes the chief complaint and urgency of the patient from a doctor-patient conversation.\n",
        "\n",
        "    Parameters:\n",
        "    - conversation (str): The full doctor-patient conversation.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Contains 'chief_complaint' and 'urgency_level' (on a scale of 1–5).\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following doctor-patient conversation.\n",
        "\n",
        "    Extract:\n",
        "    1. Chief complaint (main health issue described by the patient) – a brief sentence.\n",
        "    2. Urgency level (1 to 5), where:\n",
        "       - 1 = not urgent\n",
        "       - 5 = extremely urgent and needs immediate attention\n",
        "\n",
        "    Format your response exactly like this:\n",
        "    chief_complaint: <complaint>\n",
        "    urgency_level: <1-5>\n",
        "\n",
        "    Conversation:\n",
        "    {conversation}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    raw_output = response.content.strip()\n",
        "\n",
        "    # Parse response into dictionary\n",
        "    result = {}\n",
        "    for line in raw_output.splitlines():\n",
        "        if \":\" in line:\n",
        "            key, value = line.split(\":\", 1)\n",
        "            result[key.strip()] = value.strip()\n",
        "\n",
        "    try:\n",
        "        result[\"urgency_level\"] = int(result[\"urgency_level\"])\n",
        "    except:\n",
        "        result[\"urgency_level\"] = None\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "3rjZcwkNLZxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "emotion_tool = Tool(\n",
        "    name=\"EmotionDetectionTool\",\n",
        "    func=detect_patient_emotion,\n",
        "    description=\"Detect the patient's emotional state and return an emotion label and score from 1 to 5.\"\n",
        ")\n",
        "\n",
        "complaint_tool = Tool(\n",
        "    name=\"ChiefComplaintSummaryTool\",\n",
        "    func=summarize_chief_complaint,\n",
        "    description=\"Summarize the patient's chief complaint and determine urgency (low, medium, high).\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "jmCgnf7dMMFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate # New import for the prompt template\n",
        "\n",
        "# Define your tools (assume emotion_tool and complaint_tool are already defined)\n",
        "tools = [emotion_tool, complaint_tool]\n",
        "\n",
        "# Define the prompt template for the tool calling agent\n",
        "# This replaces the need to import TOOL_CALLING_PROMPT directly\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "\n",
        "# Create the agent\n",
        "# Remove the 'output_parser' and 'format_scratchpad' arguments\n",
        "agent = create_tool_calling_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt\n",
        ")\n",
        "\n",
        "\n",
        "# Wrap the agent into an executor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "t3v71ahhOE2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = \"\"\"\n",
        "Doctor: Hello, how are you feeling today?\n",
        "Patient: I've been having chest pains and shortness of breath. It's making me very anxious.\n",
        "Doctor: I see, let's take a closer look.\n",
        "\"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": f\"Analyze this conversation:\\n{conversation}\\n\\nPlease detect the patient's emotional state and summarize the chief complaint with urgency.\"\n",
        "})\n",
        "\n",
        "print(response[\"output\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMyQvAkGMaun",
        "outputId": "32fb4343-aaf7-40aa-e9b9-de3b2df8e919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `EmotionDetectionTool` with `I've been having chest pains and shortness of breath. It's making me very anxious.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'emotion': 'anxious', 'emotion_score': 2}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ChiefComplaintSummaryTool` with `I've been having chest pains and shortness of breath. It's making me very anxious.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m{'chief_complaint': 'The patient is experiencing chest pains and shortness of breath.', 'urgency_level': 5}\u001b[0m\u001b[32;1m\u001b[1;3mThe patient's emotional state is anxious with a score of 2, and the chief complaint is chest pains and shortness of breath with a high urgency level.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The patient's emotional state is anxious with a score of 2, and the chief complaint is chest pains and shortness of breath with a high urgency level.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = \"\"\"\n",
        "Doctor: Good morning! How are you feeling today?\n",
        "\n",
        "Patient: Good morning, Doctor. I’m feeling much better than last week, thank you.\n",
        "\n",
        "Doctor: That’s wonderful to hear. Were you able to take all the medications as prescribed?\n",
        "\n",
        "Patient: Yes, I followed the instructions exactly. I think they really helped.\n",
        "\n",
        "Doctor: Excellent. Any side effects or issues?\n",
        "\n",
        "Patient: Not really. Just a bit of drowsiness the first couple of days, but that’s gone now.\n",
        "\n",
        "Doctor: That’s perfectly normal. I'm glad you're doing well. How is your energy level?\n",
        "\n",
        "Patient: Much better. I’ve even started going on short walks again.\n",
        "\n",
        "Doctor: That’s fantastic progress! Keep that up, and we’ll gradually increase your activity. Do you have any concerns or questions?\n",
        "\n",
        "Patient: No concerns for now. Just grateful for the care.\n",
        "\n",
        "Doctor: You’re doing great. Let’s do a follow-up in two weeks to make sure things stay on track.\n",
        "\n",
        "Patient: Sounds good. Thanks again, Doctor!\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": f\"Analyze this conversation:\\n{conversation}\\n\\nPlease detect the patient's emotional state and summarize the chief complaint with urgency.\"\n",
        "})\n",
        "\n",
        "print(response[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5Uzd_okMyiX",
        "outputId": "11bddff9-dab2-4e03-9d7a-f8a00c91fb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `EmotionDetectionTool` with `The patient is feeling grateful and positive about their progress, with no concerns or negative emotions expressed.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'emotion': 'Grateful', 'emotion_score': 5}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ChiefComplaintSummaryTool` with `The patient's chief complaint is not explicitly stated, but based on the context, it appears they were being treated for an illness or condition that has improved with medication and rest. The urgency is low since the patient is feeling better and has no concerns.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m{'chief_complaint': \"The patient's condition has improved with medication and rest.\", 'urgency_level': 1}\u001b[0m\u001b[32;1m\u001b[1;3mThe patient's emotional state is detected as \"Grateful\" with a score of 5, indicating a very positive emotional state. The chief complaint summary is that the patient's condition has improved with medication and rest, and the urgency level is low (1), indicating that the patient is no longer in a critical or urgent situation.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The patient's emotional state is detected as \"Grateful\" with a score of 5, indicating a very positive emotional state. The chief complaint summary is that the patient's condition has improved with medication and rest, and the urgency level is low (1), indicating that the patient is no longer in a critical or urgent situation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task: Customer Review Extraction"
      ],
      "metadata": {
        "id": "HEKaBcpzQ1Ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Extract the customer(name & ID), product and company details\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Extract the sentiment of the customer\n",
        "\n",
        "\n",
        "\n",
        "*   What was good or bad about the product- give specific details\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EmkB8zKVTntr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel\n",
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "h-eE0TqaQ4CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewExtractionOutput(BaseModel):\n",
        "    customer_name: str\n",
        "    customer_id: str\n",
        "    product: str\n",
        "    company: str\n",
        "    sentiment: str\n",
        "    pros: str\n",
        "    cons: str\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=ReviewExtractionOutput)\n",
        "\n",
        "# Initialize your LLM\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "9fFqJ4NiQ5PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_review_text(text: str) -> str:\n",
        "    # Remove emojis and non-standard characters (basic approach)\n",
        "    text = re.sub(r'[^\\w\\s.,@#()-/:]', '', text)\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "Mk8Ff39gQ9Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_review_details(review_text: str) -> ReviewExtractionOutput:\n",
        "    cleaned_text = clean_review_text(review_text)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert assistant that extracts key details from customer reviews. Analyze the following review and extract:\n",
        "\n",
        "1. Customer's name\n",
        "2. Customer's ID\n",
        "3. Product name\n",
        "4. Company/store name\n",
        "5. Sentiment of the customer (positive, negative, neutral)\n",
        "6. Specific pros (what was good about the product)\n",
        "7. Specific cons (what was bad about the product)\n",
        "\n",
        "Do NOT add any explanations or extra text.\n",
        "\n",
        "Review:\n",
        "\\\"\\\"\\\"{cleaned_text}\\\"\\\"\\\"\n",
        "\n",
        "Strictly respond following the below schema:\n",
        "{parser.get_format_instructions()}\n",
        "\"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    cleaned_output = response.content.strip()\n",
        "    parsed_output = parser.parse(cleaned_output)\n",
        "    return parsed_output"
      ],
      "metadata": {
        "id": "1bFzxifeRAwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"\"\"@Customer: Varun D. Kapoor (ID#: CRM5543219) | Purchase Date: 22/10/2023 | Store: Croma Electronics, DLF Mall Branch, Sector 18, Noida, UP - 201301 | Product: Pebble BassX Prime™ Wireless Speaker (#PBL-SPK22) | Order #: CRM/DLF/2023/10/7788 ✨ What a FANTASTIC buy @ just ₹2,499/-! Been using this Pebble speaker for 3 weeks & honestly amazed by the value for money 🎵. Sales rep @Amit (ID#CR567) recommended this over expensive brands & boy was he right! Let me tell you why this budget speaker is punching way above its weight -> First off, the BASS!!! For this price point, totally unexpected depth & clarity = perfect party companion 🔊. Battery life is IMPRESSIVE: advertised 8hrs but I'm getting solid 9.5hrs on 60% volume!!! RGB lights sync w/ music = creates nice ambiance (can be turned off too). Bluetooth 5.0 connection = zero lag & connects instantly w/ my iPhone & laptop. Range is solid, works through walls up to ~30ft ⚡. Delivery/setup experience was smooth: ordered @ 11am, delivered same day @ 4pm exactly as promised. Really appreciate the thoughtful additions: aux cable included + Type-C charging (finally!) + voice assistant compatible + IPX6 water resistance (survived a small rain splash already!) 💫. Sound quality for calls is crystal clear - using it for WFH meetings daily. The dual pairing feature lets me connect 2 phones simultaneously = super convenient for family use 📱. Build quality feels sturdy despite plastic body - survived 2 accidental drops w/o a scratch! Called customer support (#1800-123-4567) to understand equalizer settings → got helpful guidance in 1st attempt. Store manager @Deepak Sinha even shared his personal WhatsApp for any issues = great customer service! Only tiny suggestion: wish the manual was bit more detailed re: EQ settings. Getting so many compliments during house parties - friends can't believe the price when they hear the sound quality! Definitely exceeded expectations for a budget speaker - perfect balance of features & affordability 🌟. Already ordered another one for my parents! Big thumbs up to Pebble & Croma for this value-packed product. #PebbleSpeaker #BudgetBuy #QualitySound #PerfectChoice #HappyPurchase [Posted: 13/11/2023 | Review ID: REV34567890]\"\"\"\n",
        "\n",
        "result = extract_review_details(review_text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0L9Bq-CRFZ4",
        "outputId": "0527b142-b954-43ac-ad3a-1453a2f56509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_name='Varun D. Kapoor' customer_id='CRM5543219' product='Pebble BassX Prime Wireless Speaker (#PBL-SPK22)' company='Croma Electronics' sentiment='positive' pros='value for money, deep bass, impressive battery life, RGB lights, Bluetooth 5.0 connection, aux cable included, Type-C charging, voice assistant compatible, IPX6 water resistance, crystal clear sound quality for calls, dual pairing feature' cons='manual could be more detailed regarding EQ settings'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"\"\"@Customer: Aisha R. Sheikh (ID#: CRM9934567) | Purchase Date: 15/09/2023 | Store: Croma Electronics, Oberoi Mall Branch, Western Express Highway, Goregaon (E), Mumbai - 400063 | Product: Dyson Supersonic™ Hair Dryer (#HD07) | Order #: CRM/OBR/2023/09/6543 ⭐ Overall satisfied w/ my Dyson purchase though the price point (₹44,900/-) definitely makes you think twice! After 2 months of regular use, here's my balanced take -> The good stuff first: heat control is EXCELLENT, never burns my hair like old dryer & the magnetic attachments are quite clever 👍. Sales consultant @Ritu (ID#CR234) was knowledgeable & didn't oversell, appreciated her honesty about product features. The technology is impressive = consistent temp control + ion technology does make hair notably smoother ✨. Noise level is definitely lower than traditional dryers (but not \"whisper-quiet\" as advertised). Drying time reduced by ~40% which helps on busy mornings! Build quality feels premium & the box packaging was luxurious 📦. Now the not-so-perfect parts: The cord could be longer, sometimes awkward to maneuver @ current length. Weight distribution takes getting used to - different from traditional dryers but not necessarily better/worse 🤔. Installation/demo was scheduled 3-5pm, person arrived @ 5:30pm (bit late but acceptable). Price of additional attachments = quite steep! Called customer service (#1800-123-4567) once for attachment query → decent response time, somewhat helpful. Minor annoyance: cold shot button needs to be held down continuously = slightly inconvenient. Store manager @Vikas Patel provided good support w/ warranty registration. Would I recommend it? Yes, but only if you're okay w/ premium pricing & really care about hair care! Not a must-have but definitely a nice-to-have luxury item. Battery life & performance consistent so far = no complaints. Comes with 2yr warranty which is reassuring for expensive purchase. Fair product, works as advertised, but prepare for the investment! #DysonHair #PremiumProduct #DecentChoice #GoodEnough #ExpensiveButOk [Posted: 13/11/2023 | Review ID: REV45678901]\"\"\"\n",
        "\n",
        "result = extract_review_details(review_text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1UfPElWRUL9",
        "outputId": "2cd922ba-a1e7-460d-f643-f7c212940ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_name='Aisha R. Sheikh' customer_id='CRM9934567' product='Dyson Supersonic Hair Dryer (#HD07)' company='Croma Electronics' sentiment='positive' pros='heat control is EXCELLENT, magnetic attachments are clever, sales consultant was knowledgeable, technology is impressive, consistent temp control, ion technology makes hair smoother, noise level is lower, drying time reduced, build quality feels premium' cons='price point is high, cord could be longer, weight distribution takes getting used to, installation/demo was late, price of additional attachments is steep, cold shot button needs to be held down continuously'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"\"\"@Customer: Priya S. Mehta (ID#: CRM8765432) | Purchase Date: 05/10/2023 | Store: Croma Electronics, Phoenix MarketCity Branch, 1st Floor, LBS Marg, Kurla (W), Mumbai - 400070 | Product: Philips ProBlend™ Series 700W Juicer Mixer Grinder (#HL7763/80) | Order #: CRM/PHX/2023/10/8876 ✨ ABSOLUTELY IN LOVE w/ my new Philips JMG!!! Best ₹12,999/- ever spent @ Croma! Been using this powerhouse daily for >1 month now & can't stop raving about it 🌟. The 700W motor is a BEAST - transforms hard vegetables into silky smooth juice in seconds!!! Special shoutout to sales executive @Neha (ID#CR456) who gave excellent demo & helped choose perfect model for my family of 4. The 5 different speed settings + pulse function ➡️ game changer for different recipes! Made everything from smooth apple juice to tough coconut chutney = PERFECT results every time 😊. Love the special features: Auto-cut off protection (safety first!) + Anti-drip spout (no more counter mess!) + Extra-wide 75mm feeding tube (fits whole apples!!!). Super quiet compared to my old mixer - can blend early morning w/o waking kids 🎯. Installation & demo was scheduled 2-4pm, team arrived @ exactly 2:15pm! Very professional setup + explained all features thoroughly. The complimentary recipe book = BONUS! Already tried 8 recipes & each turned out amazing ⭐. Build quality is exceptional - all 3 jars feel premium & super sturdy. Sharp stainless-steel blades + 2yr warranty = total peace of mind! Power consumption very reasonable - negligible difference in electricity bill. Best part -> cleaning is SUPER EASY! All parts are dishwasher safe & come apart easily. No hidden corners where pulp gets stuck 💫. Customer service experience was outstanding - had a small query about attachments, called helpline (#1800-123-4567) → resolved in 5 mins! Store manager @Rohit Singh even called after 1 week to check if everything working fine = GREAT after-sales support! Getting so many compliments on my fresh juices & smoothies. Already recommended to 5 friends - 2 have bought same model! 100% value for money & worth every rupee. Thank you Croma & Philips for this amazing product!!! #HappyCustomer #PhilipsJMG #WorthEveryPenny #HealthyLiving #PerfectChoice [Posted: 13/11/2023 | Review ID: REV23456789]\"\"\"\n",
        "\n",
        "result = extract_review_details(review_text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTf73lI5Risj",
        "outputId": "6cefda6a-6cc9-4985-99e9-2a39d7a5e072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_name='Priya S. Mehta' customer_id='CRM8765432' product='Philips ProBlend Series 700W Juicer Mixer Grinder (#HL7763/80)' company='Croma Electronics' sentiment='positive' pros='700W motor, 5 different speed settings, pulse function, Auto-cut off protection, Anti-drip spout, Extra-wide 75mm feeding tube, super quiet, exceptional build quality, sharp stainless-steel blades, 2yr warranty, easy cleaning, outstanding customer service' cons='None'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Structured format:"
      ],
      "metadata": {
        "id": "gr_FmX0TTfR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "NIQa0bYAS2ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [\n",
        "    # Review 1\n",
        "    \"\"\"@Customer: Varun D. Kapoor (ID#: CRM5543219) | Purchase Date: 22/10/2023 | Store: Croma Electronics, DLF Mall Branch, Sector 18, Noida, UP - 201301 | Product: Pebble BassX Prime™ Wireless Speaker (#PBL-SPK22) | Order #: CRM/DLF/2023/10/7788 ✨ What a FANTASTIC buy @ just ₹2,499/-! Been using this Pebble speaker for 3 weeks & honestly amazed by the value for money 🎵. Sales rep @Amit (ID#CR567) recommended this over expensive brands & boy was he right! Let me tell you why this budget speaker is punching way above its weight -> First off, the BASS!!! For this price point, totally unexpected depth & clarity = perfect party companion 🔊. Battery life is IMPRESSIVE: advertised 8hrs but I'm getting solid 9.5hrs on 60% volume!!! RGB lights sync w/ music = creates nice ambiance (can be turned off too). Bluetooth 5.0 connection = zero lag & connects instantly w/ my iPhone & laptop. Range is solid, works through walls up to ~30ft ⚡. Delivery/setup experience was smooth: ordered @ 11am, delivered same day @ 4pm exactly as promised. Really appreciate the thoughtful additions: aux cable included + Type-C charging (finally!) + voice assistant compatible + IPX6 water resistance (survived a small rain splash already!) 💫. Sound quality for calls is crystal clear - using it for WFH meetings daily. The dual pairing feature lets me connect 2 phones simultaneously = super convenient for family use 📱. Build quality feels sturdy despite plastic body - survived 2 accidental drops w/o a scratch! Called customer support (#1800-123-4567) to understand equalizer settings → got helpful guidance in 1st attempt. Store manager @Deepak Sinha even shared his personal WhatsApp for any issues = great customer service! Only tiny suggestion: wish the manual was bit more detailed re: EQ settings. Getting so many compliments during house parties - friends can't believe the price when they hear the sound quality! Definitely exceeded expectations for a budget speaker - perfect balance of features & affordability 🌟. Already ordered another one for my parents! Big thumbs up to Pebble & Croma for this value-packed product. #PebbleSpeaker #BudgetBuy #QualitySound #PerfectChoice #HappyPurchase [Posted: 13/11/2023 | Review ID: REV34567890]\"\"\",  # truncated for brevity\n",
        "    # Review 2\n",
        "    \"\"\"@Customer: Aisha R. Sheikh (ID#: CRM9934567) | Purchase Date: 15/09/2023 | Store: Croma Electronics, Oberoi Mall Branch, Western Express Highway, Goregaon (E), Mumbai - 400063 | Product: Dyson Supersonic™ Hair Dryer (#HD07) | Order #: CRM/OBR/2023/09/6543 ⭐ Overall satisfied w/ my Dyson purchase though the price point (₹44,900/-) definitely makes you think twice! After 2 months of regular use, here's my balanced take -> The good stuff first: heat control is EXCELLENT, never burns my hair like old dryer & the magnetic attachments are quite clever 👍. Sales consultant @Ritu (ID#CR234) was knowledgeable & didn't oversell, appreciated her honesty about product features. The technology is impressive = consistent temp control + ion technology does make hair notably smoother ✨. Noise level is definitely lower than traditional dryers (but not \"whisper-quiet\" as advertised). Drying time reduced by ~40% which helps on busy mornings! Build quality feels premium & the box packaging was luxurious 📦. Now the not-so-perfect parts: The cord could be longer, sometimes awkward to maneuver @ current length. Weight distribution takes getting used to - different from traditional dryers but not necessarily better/worse 🤔. Installation/demo was scheduled 3-5pm, person arrived @ 5:30pm (bit late but acceptable). Price of additional attachments = quite steep! Called customer service (#1800-123-4567) once for attachment query → decent response time, somewhat helpful. Minor annoyance: cold shot button needs to be held down continuously = slightly inconvenient. Store manager @Vikas Patel provided good support w/ warranty registration. Would I recommend it? Yes, but only if you're okay w/ premium pricing & really care about hair care! Not a must-have but definitely a nice-to-have luxury item. Battery life & performance consistent so far = no complaints. Comes with 2yr warranty which is reassuring for expensive purchase. Fair product, works as advertised, but prepare for the investment! #DysonHair #PremiumProduct #DecentChoice #GoodEnough #ExpensiveButOk [Posted: 13/11/2023 | Review ID: REV45678901]\"\"\",\n",
        "    # Review 3\n",
        "    \"\"\"@Customer: Priya S. Mehta (ID#: CRM8765432) | Purchase Date: 05/10/2023 | Store: Croma Electronics, Phoenix MarketCity Branch, 1st Floor, LBS Marg, Kurla (W), Mumbai - 400070 | Product: Philips ProBlend™ Series 700W Juicer Mixer Grinder (#HL7763/80) | Order #: CRM/PHX/2023/10/8876 ✨ ABSOLUTELY IN LOVE w/ my new Philips JMG!!! Best ₹12,999/- ever spent @ Croma! Been using this powerhouse daily for >1 month now & can't stop raving about it 🌟. The 700W motor is a BEAST - transforms hard vegetables into silky smooth juice in seconds!!! Special shoutout to sales executive @Neha (ID#CR456) who gave excellent demo & helped choose perfect model for my family of 4. The 5 different speed settings + pulse function ➡️ game changer for different recipes! Made everything from smooth apple juice to tough coconut chutney = PERFECT results every time 😊. Love the special features: Auto-cut off protection (safety first!) + Anti-drip spout (no more counter mess!) + Extra-wide 75mm feeding tube (fits whole apples!!!). Super quiet compared to my old mixer - can blend early morning w/o waking kids 🎯. Installation & demo was scheduled 2-4pm, team arrived @ exactly 2:15pm! Very professional setup + explained all features thoroughly. The complimentary recipe book = BONUS! Already tried 8 recipes & each turned out amazing ⭐. Build quality is exceptional - all 3 jars feel premium & super sturdy. Sharp stainless-steel blades + 2yr warranty = total peace of mind! Power consumption very reasonable - negligible difference in electricity bill. Best part -> cleaning is SUPER EASY! All parts are dishwasher safe & come apart easily. No hidden corners where pulp gets stuck 💫. Customer service experience was outstanding - had a small query about attachments, called helpline (#1800-123-4567) → resolved in 5 mins! Store manager @Rohit Singh even called after 1 week to check if everything working fine = GREAT after-sales support! Getting so many compliments on my fresh juices & smoothies. Already recommended to 5 friends - 2 have bought same model! 100% value for money & worth every rupee. Thank you Croma & Philips for this amazing product!!! #HappyCustomer #PhilipsJMG #WorthEveryPenny #HealthyLiving #PerfectChoice [Posted: 13/11/2023 | Review ID: REV23456789]\"\"\",\n",
        "\n",
        "]\n",
        "\n",
        "# Step 6: Process all in parallel\n",
        "def process_all_reviews(review_list):\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        results = list(executor.map(extract_review_details, review_list))\n",
        "    return results\n",
        "\n",
        "# Step 7: Format and display result\n",
        "def display_results(results):\n",
        "    table = []\n",
        "    for r in results:\n",
        "        table.append([\n",
        "            r.customer_name,\n",
        "            r.customer_id,\n",
        "            r.product,\n",
        "            r.company,\n",
        "            r.sentiment,\n",
        "            r.pros[:50] + ('...' if len(r.pros) > 50 else ''),\n",
        "            r.cons[:50] + ('...' if len(r.cons) > 50 else '')\n",
        "        ])\n",
        "    headers = [\"Customer\", \"ID\", \"Product\", \"Company\", \"Sentiment\", \"Pros\", \"Cons\"]\n",
        "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))"
      ],
      "metadata": {
        "id": "JpjzOxloScar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = process_all_reviews(reviews)\n",
        "display_results(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbVBLc82SyV0",
        "outputId": "546893c6-dcd6-4cdd-9be5-aee72f87efe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+----------------------------------------------------------------+-------------------+-------------+-------------------------------------------------------+-------------------------------------------------------+\n",
            "| Customer        | ID         | Product                                                        | Company           | Sentiment   | Pros                                                  | Cons                                                  |\n",
            "+=================+============+================================================================+===================+=============+=======================================================+=======================================================+\n",
            "| Varun D. Kapoor | CRM5543219 | Pebble BassX Prime Wireless Speaker (#PBL-SPK22)               | Croma Electronics | positive    | value for money, deep bass, impressive battery lif... | manual could be more detailed regarding EQ setting... |\n",
            "+-----------------+------------+----------------------------------------------------------------+-------------------+-------------+-------------------------------------------------------+-------------------------------------------------------+\n",
            "| Aisha R. Sheikh | CRM9934567 | Dyson Supersonic Hair Dryer (#HD07)                            | Croma Electronics | positive    | heat control is EXCELLENT, magnetic attachments ar... | price point is high, cord could be longer, weight ... |\n",
            "+-----------------+------------+----------------------------------------------------------------+-------------------+-------------+-------------------------------------------------------+-------------------------------------------------------+\n",
            "| Priya S. Mehta  | CRM8765432 | Philips ProBlend Series 700W Juicer Mixer Grinder (#HL7763/80) | Croma Electronics | positive    | 700W motor, 5 different speed settings, pulse func... | None                                                  |\n",
            "+-----------------+------------+----------------------------------------------------------------+-------------------+-------------+-------------------------------------------------------+-------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}